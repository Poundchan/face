<!DOCTYPE html>
<html>
<head>
    <script src="face-api.js"></script>
    <script src="js/commons.js"></script>
    <script src="js/faceDetectionControls.js"></script>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>
<body>

<div id="bsm-container">

    <div class="progress" id="loader">
        <div class="indeterminate"></div>
    </div>
    <div id="bsm-video">
        <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
        <canvas id="overlay"/>
    </div>

    <div class="row side-by-side" style="display: none">

        <!-- face_detector_selection_control -->
        <div id="face_detector_selection_control" class="row input-field" style="margin-right: 20px;">
            <select id="selectFaceDetector">
                <option value="ssd_mobilenetv1">SSD Mobilenet V1</option>
                <option value="tiny_face_detector">Tiny Face Detector</option>
                <option value="mtcnn">MTCNN</option>
            </select>
            <label>Select Face Detector</label>
        </div>

    </div>

    <!-- tiny_face_detector_controls -->
    <span id="tiny_face_detector_controls" style="display: none">
      <div class="row side-by-side">

        <div class="row">
          <label for="scoreThreshold">Score Threshold:</label>
          <input disabled value="0.7" id="scoreThreshold" type="text" class="bold">
        </div>
      </div>
    </span>
    <!-- tiny_face_detector_controls -->
    <!-- mtcnn_controls -->
</div>
</body>

<script>
	let forwardTimes = []
	let withBoxes = true

	function onChangeHideBoundingBoxes(e) {
		withBoxes = !$(e.target).prop('checked')
	}

	async function onPlay() {
		const displaySize = {width: 925, height: 520}
		// resize the overlay canvas to the input dimensions
		const canvas = document.getElementById('overlay')
		faceapi.matchDimensions(canvas, displaySize)

		const videoEl = $('#inputVideo').get(0)

		if (videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
			return setTimeout(() => onPlay())

		const options = getFaceDetectorOptions()

		const detectionsWithExpressions = await faceapi
			.detectAllFaces(videoEl, options)
			.withFaceLandmarks()
			.withFaceExpressions()

		// 添加年龄
		const results = await faceapi.detectAllFaces(videoEl, options)
			.withFaceLandmarks()
			.withAgeAndGender()


		// resize the detected boxes and landmarks in case your displayed image has a different size than the original
		const resizedResults = faceapi.resizeResults(detectionsWithExpressions, displaySize)
		// draw detections into the canvas
		const drawDetectionOptions = {
			lineWidth: 2,
			textColor: 'red',
			boxColor: 'red',
			withScore: true
		}
		faceapi.draw.drawDetections(canvas, resizedResults,drawDetectionOptions)
		// draw a textbox displaying the face expressions with minimum probability into the canvas
		const minProbability = 0.05
		faceapi.draw.drawFaceExpressions(canvas, resizedResults, minProbability)

		results.forEach(result => {
			const {age, gender, genderProbability} = result
			new faceapi.draw.DrawTextField(
				[
					`${faceapi.round(age, 0)} years`,
					`${gender} (${faceapi.round(genderProbability)})`
				],
				result.detection.box.topLeft
			).draw(canvas)
		})

		setTimeout(() => onPlay(),70)
	}

	async function run() {
		// load face detection and face expression recognition models
		await changeFaceDetector(TINY_FACE_DETECTOR)
		faceapi.tf.getBackend()
		//await faceapi.nets.ssdMobilenetv1.load('/')
		await faceapi.loadFaceLandmarkModel('/')
		await faceapi.loadFaceExpressionModel('/')
		await faceapi.nets.ageGenderNet.load('/')

		changeInputSize(416)

		// try to access users webcam and stream the images
		// to the video element
		const stream = await navigator.mediaDevices.getUserMedia({video: {width: 925, height: 520}})
		const videoEl = $('#inputVideo').get(0)
		videoEl.srcObject = stream
	}

	function updateResults() {
	}

	$(document).ready(function () {
		initFaceDetectionControls()
		run()
	})
</script>
</body>
</html>
